import yaml
import mlflow
import streamlit as st
import threading
from retrieval import retrieve_documents
from llm_model import generate_response
from mlflow_logger import log_to_mlflow
from config_loader import config  


mlflow.set_experiment(config["mlflow"]["experiment_name"])

# Keep track of background threads
background_threads = []
@mlflow.trace
def process_query(user_input):
    # Retrieve documents
    context, cosine_score, retrieved_docs_with_scores, top_doc = retrieve_documents(user_input)
    if top_doc["metadata"]["source"]== "00-Sports-Articles/vulgar.txt":
        result = "no comment"
        prompt = f"Question: {user_input}"
    else:
        # Construct the full prompt
        if cosine_score <= config["score"]["thresold"]:
            prompt = f"Context: {context}\n\nQuestion: {user_input}"
        else:
            prompt = f"Question: {user_input}"

        # Query Llama 3.2 with retrieved context
        result = generate_response(prompt)

    return result, context, cosine_score, retrieved_docs_with_scores, prompt, top_doc

# Streamlit UI
st.title("ðŸ” LLM RAG Chatbot with MLflow & ChromaDB")
st.write("Ask a question and get responses from Llama 3.2!")

# User input
user_input = st.text_input("ðŸ’¬ Ask Your question:", "")

if st.button("Submit"):
    if user_input.strip():
        with mlflow.start_run() as active_run:
            run_id = active_run.info.run_id

            # Process query
            result, context, cosine_score, retrieved_docs_with_scores, prompt, top_doc = process_query(user_input)

            # Log asynchronously
            thread = threading.Thread(
                target=log_to_mlflow, 
                args=(run_id, user_input, prompt, result, [top_doc] if top_doc else [], cosine_score)
            )
            thread.daemon = True
            thread.start()
            background_threads.append(thread)

            # Display response
            st.subheader("ðŸ¤– Model Response:")
            st.write(result.get("response", "No response generated."))

            st.subheader("ðŸ“œ Top Retrieved Document Snippet:")
            st.write(context[:500])

            st.subheader("ðŸ”¢ Cosine Similarity Score (Top Match):")
            st.write(round(cosine_score, 4))

            # Show retrieved documents
            if retrieved_docs_with_scores:
                st.subheader("ðŸ“š Retrieved Documents and Scores:")
                for i, (doc, score) in enumerate(retrieved_docs_with_scores, 1):
                    doc_name = doc.metadata.get("source", "Unknown File")
                    st.write(f"{i}. **Doc:** {doc_name[:50]}... | **Score:** {round(score, 4)}")
            else:
                st.warning("âš ï¸ No relevant document found.")
    else:
        st.error("âŒ Please enter a question.")
